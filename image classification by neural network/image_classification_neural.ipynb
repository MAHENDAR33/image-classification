{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c2cd227-bc86-4177-b025-503bedd46c2f",
   "metadata": {},
   "source": [
    "### This code builds a Convolutional Neural Network (CNN) using the ResNet50 model as a base for image classification. After loading the pre-trained ResNet50 model without its top layers, additional Dense and Dropout layers are added to fine-tune the model specifically for the userâ€™s dataset, which contains 5 classes. Hyperparameters like the learning rate, number of neurons in dense layers, and dropout rate are adjusted to optimize the model's performance. The ImageDataGenerator class is used to normalize and split the image dataset into training and validation sets. Finally, the model is compiled with categorical cross-entropy loss and trained for 10 epochs, tracking both training and validation performance metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e83ed80-30f8-4836-bae9-d6783e7ac906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 181 images belonging to 5 classes.\n",
      "Found 9 images belonging to 5 classes.\n",
      "Epoch 1/10\n",
      "16/18 [=========================>....] - ETA: 9s - loss: 1.6524 - accuracy: 0.2914 "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "\n",
    "# Set image dimensions\n",
    "img_height, img_width = 224, 224\n",
    "\n",
    "# Load base model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Creating model\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())  # Global pooling layer to reduce dimensions\n",
    "\n",
    "# Tuning hyperparameters\n",
    "num_classes = 5  # Change this to the number of classes in your dataset\n",
    "neurons_layer1 = 128  # Number of neurons in the first Dense layer\n",
    "neurons_layer2 = 64   # Number of neurons in the second Dense layer\n",
    "dropout_rate = 0.5    # Dropout rate\n",
    "\n",
    "model.add(Dense(neurons_layer1, activation='relu'))\n",
    "model.add(tf.keras.layers.Dropout(dropout_rate))  \n",
    "model.add(Dense(neurons_layer2, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))  \n",
    "\n",
    "# Compile model with a different learning rate\n",
    "learning_rate = 0.0001 \n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "# Data generator for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values \n",
    "    validation_split=0.2  # Reserve 20% of data for validation\n",
    ")\n",
    "\n",
    "# a)Training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\Mahendar\\\\flaskproject\\\\sports_person_classification\\\\static\\\\images\",\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=10,\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='training'  # Set as training data\n",
    ")\n",
    "\n",
    "# b)Validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\Mahendar\\\\flaskproject\\\\sports_person_classification\\\\static\\\\test_images\",\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=5,\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='validation'  # Set as validation data\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=10 \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a0cfe2-f011-4388-be08-4f2ad1f92417",
   "metadata": {},
   "source": [
    "### This code builds an image classification model using the VGG16 architecture, pre-trained on ImageNet, to leverage powerful, learned features. After loading VGG16 without its final classification layers, the model adds custom layers, including a pooling layer to condense the features, a dense layer with 256 neurons, and a dropout layer to reduce overfitting. The final layer outputs probabilities for each class, based on the number of categories in the dataset. The model is compiled with the Adam optimizer and categorical cross-entropy for multi-class classification. Data is prepared using an ImageDataGenerator to scale images and split them into training and validation sets. The model then trains for 10 epochs, using both the training and validation sets to monitor performance and adjust parameters as it learns to classify the dataset images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7403dff6-4229-4c07-9220-69866ab3d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import VGG16  \n",
    "# Load base model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "\n",
    "# Repeating the model-building process with the new base model...\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(256, activation='relu'))  # Increasing neurons for potentially better learning\n",
    "model.add(tf.keras.layers.Dropout(dropout_rate))  # Regularization\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), metrics=['accuracy'])\n",
    "\n",
    "# The rest of the code remains the same...\n",
    "# Data generator for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,  # Normalize pixel values to [0, 1]\n",
    "    validation_split=0.2  # Reserve 20% of data for validation\n",
    ")\n",
    "\n",
    "# Training data\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\Mahendar\\\\flaskproject\\\\sports_person_classification\\\\static\\\\images\",\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=10,\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='training'  # Set as training data\n",
    ")\n",
    "\n",
    "# Validation data\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    \"C:\\\\Users\\\\Mahendar\\\\flaskproject\\\\sports_person_classification\\\\static\\\\test_images\",\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=5,\n",
    "    class_mode='categorical',  # Multi-class classification\n",
    "    subset='validation'  # Set as validation data\n",
    ")\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    epochs=10  # Increase the number of epochs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580376a3-80ad-49df-8aee-044904d76664",
   "metadata": {},
   "source": [
    "#### disadavantages of neural network model is more, its very complicated to handle i am not going to suggest this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934fb3c4-3a23-447d-937d-0a4907fc9b88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
